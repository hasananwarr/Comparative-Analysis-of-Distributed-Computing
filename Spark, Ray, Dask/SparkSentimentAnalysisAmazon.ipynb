{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GEzjGg7Pt3h",
        "outputId": "20e5a57f-80cb-4088-b40c-970504d1c155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.5.tar.gz (317.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Collecting synapseml==0.11.3\n",
            "  Downloading synapseml-0.11.3-py2.py3-none-any.whl.metadata (642 bytes)\n",
            "Collecting py4j==0.10.9.7 (from pyspark)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Downloading synapseml-0.11.3-py2.py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m550.0/550.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.5-py2.py3-none-any.whl size=317747859 sha256=ec7f21a50f20c22ce5161e4fce642e9c31d1855a9826785440dd415b3a8f78ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/7f/b4/0e68c6d8d89d2e582e5498ad88616c16d7c19028680e9d3840\n",
            "Successfully built pyspark\n",
            "Installing collected packages: synapseml, py4j, pyspark, pyngrok\n",
            "Successfully installed py4j-0.10.9.7 pyngrok-7.2.3 pyspark-3.5.5 synapseml-0.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark pandas nltk kagglehub pyngrok kaggle synapseml==0.11.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, udf\n",
        "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pyspark.sql.functions import col, isnan, when\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jk4iwq9P8qY",
        "outputId": "0fbd61bd-1ee4-4492-ad46-6d1636c48611"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"SparkBenchmark\").getOrCreate()\n",
        "\n",
        "print(spark)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfMJKp8uP974",
        "outputId": "51b27660-e7cd-41f6-e62c-bc24000bf71d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7a1e06de5190>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ngrok authtoken xxxxxxx\n",
        "#configuration = (SparkSession.builder\n",
        "#         .appName(\"NYC Taxi Price Prediction\")\n",
        "#         .config(\"spark.driver.memory\", \"100g\")\n",
        "#         .config(\"spark.executor.memory\", \"50g\")\n",
        "#         .config(\"spark.executor.cores\", \"4\")\n",
        "#         .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
        "#         .config(\"spark.dynamicAllocation.minExecutors\", \"2\")\n",
        "#         .config(\"spark.dynamicAllocation.maxExecutors\", \"10\")\n",
        "#         .config(\"spark.sql.shuffle.partitions\", \"20\")\n",
        "#      )\n",
        "\n",
        "#spark = configuration.getOrCreate()\n",
        "#print(\"Spark initialized!\")"
      ],
      "metadata": {
        "id": "2tmbipU7UzRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_extract(dataset, file_name):\n",
        "    download_path = \"./downloads\"\n",
        "    zip_file_path = file_name + \".zip\"\n",
        "    command = f\"kaggle datasets download {dataset} --file {file_name}\"\n",
        "    os.system(command)\n",
        "\n",
        "    os.system(f\"unzip {zip_file_path} -d {download_path}\")\n",
        "    extracted_file_path = os.path.join(download_path, file_name)\n",
        "\n",
        "    return os.path.join(download_path, file_name)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text.lower() if text else \"\")\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words and len(word) > 2]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "cq4R0IGLQVg7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset = \"cynthiarempel/amazon-us-customer-reviews-dataset\"\n",
        "file_name = \"amazon_reviews_us_Wireless_v1_00.tsv\"\n",
        "\n",
        "file_path = download_and_extract(dataset, file_name)\n",
        "spark_df = spark.read.csv(\n",
        "    file_path,\n",
        "    sep=\"\\t\",\n",
        "    header=True,\n",
        "    inferSchema=True,\n",
        "    multiLine=True\n",
        ").sample(fraction=0.1, seed=42)\n",
        "\n",
        "print(f\"Dataset loaded successfully with {spark_df.count()} rows.\")\n",
        "spark_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPTlshp0QbjN",
        "outputId": "609db0e8-4588-457e-9711-50da8f056c4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully with 900773 rows.\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|         US|   48086021|R3MWLXLNO21PDQ|B00IP1MQNK|     488006702|Lumsing 10400mah ...|        Wireless|          5|            0|          0|   N|                Y|          Five Stars|         Works great| 2015-08-31|\n",
            "|         US|   12218556|R26VY1L1FD3LPU|B00BJN45GM|      47788188|OtterBox Defender...|        Wireless|          5|            0|          0|   N|                Y|          Five Stars|  Awesome, thank you| 2015-08-31|\n",
            "|         US|   16264332|R1G6333JHJNEUQ|B00Q3I68TU|     974085141|LilGadgets Connec...|        Wireless|          5|            0|          0|   N|                Y|Great headphones ...|We love these hea...| 2015-08-31|\n",
            "|         US|   10129564|R1PO1FLLNSK07D|B00N0QV4J2|     821410487|MyBat Tribe Impre...|        Wireless|          5|            0|          0|   N|                N|          Five Stars|Very sturdy, keep...| 2015-08-31|\n",
            "|         US|    4439414|R3QP6739WN6HCP|B00T6P03YS|     546887936|Hybridized Clarit...|        Wireless|          1|            0|          1|   N|                Y|Gave it away for ...|Not what I expect...| 2015-08-31|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_udf = udf(preprocess_text, ArrayType(StringType()))\n",
        "\n",
        "preprocessed_df = spark_df \\\n",
        "    .withColumn(\"review_body\", lower(col(\"review_body\"))) \\\n",
        "    .withColumn(\"review_body\", regexp_replace(col(\"review_body\"), r\"http\\S+|www\\S+|https\\S+\", \"\")) \\\n",
        "    .withColumn(\"review_body\", regexp_replace(col(\"review_body\"), r\"[^a-zA-Z\\s]\", \"\")) \\\n",
        "    .withColumn(\"review_body\", regexp_replace(col(\"review_body\"), r\"\\s+\", \" \")) \\\n",
        "    .withColumn(\"tokens\", preprocess_udf(col(\"review_body\"))) \\\n",
        "    .withColumn(\"sentiment\", (col(\"star_rating\") > 3).cast(IntegerType()))\n",
        "\n",
        "preprocessed_df = preprocessed_df.filter(col(\"star_rating\").isNotNull())\n",
        "preprocessed_df = preprocessed_df.withColumn(\"sentiment\", (col(\"star_rating\") > 3).cast(IntegerType()))\n",
        "preprocessed_df = preprocessed_df.filter(col(\"sentiment\").isNotNull() & ~isnan(col(\"sentiment\")))\n",
        "\n",
        "\n",
        "preprocessed_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_DbCJduQRyO",
        "outputId": "4e162da8-7454-4aec-fff6-8e69566a8588"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+----------------------------------------------------------------------------------------------+----------------+-----------+-------------+-----------+----+-----------------+-----------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|marketplace|customer_id|review_id     |product_id|product_parent|product_title                                                                                 |product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|review_headline                                      |review_body                                                                                                                                                                                                  |review_date|tokens                                                                                                                   |sentiment|\n",
            "+-----------+-----------+--------------+----------+--------------+----------------------------------------------------------------------------------------------+----------------+-----------+-------------+-----------+----+-----------------+-----------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|US         |48086021   |R3MWLXLNO21PDQ|B00IP1MQNK|488006702     |Lumsing 10400mah external battery                                                             |Wireless        |5          |0            |0          |N   |Y                |Five Stars                                           |works great                                                                                                                                                                                                  |2015-08-31 |[works, great]                                                                                                           |1        |\n",
            "|US         |12218556   |R26VY1L1FD3LPU|B00BJN45GM|47788188      |OtterBox Defender Series Case for HTC One                                                     |Wireless        |5          |0            |0          |N   |Y                |Five Stars                                           |awesome thank you                                                                                                                                                                                            |2015-08-31 |[awesome, thank]                                                                                                         |1        |\n",
            "|US         |16264332   |R1G6333JHJNEUQ|B00Q3I68TU|974085141     |LilGadgets Connect+ Premium Volume Limited Wired Headphones with SharePort for Children / Kids|Wireless        |5          |0            |0          |N   |Y                |Great headphones for kids                            |we love these headphones we had a pair each for our and year old they loved them and thought it was great that they could share one device but each have their own set of headphones very comfortable as well|2015-08-31 |[love, headphones, pair, year, old, loved, thought, great, could, share, one, device, set, headphones, comfortable, well]|1        |\n",
            "|US         |10129564   |R1PO1FLLNSK07D|B00N0QV4J2|821410487     |MyBat Tribe Impression MyJacket Wallet with Diamante Belt for LG MS323 Optimus L70  - Blue    |Wireless        |5          |0            |0          |N   |N                |Five Stars                                           |very sturdy keeps phone nice and safe                                                                                                                                                                        |2015-08-31 |[sturdy, keeps, phone, nice, safe]                                                                                       |1        |\n",
            "|US         |4439414    |R3QP6739WN6HCP|B00T6P03YS|546887936     |Hybridized Clarity Clear back panel                                                           |Wireless        |1          |0            |1          |N   |Y                |Gave it away for my son to play with don't waste your|not what i expected at all online description misleading gave it away for my son to play with dont waste your money                                                                                          |2015-08-31 |[expected, online, description, misleading, gave, away, son, play, dont, waste, money]                                   |0        |\n",
            "+-----------+-----------+--------------+----------+--------------+----------------------------------------------------------------------------------------------+----------------+-----------+-------------+-----------+----+-----------------+-----------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hashing_tf = HashingTF(inputCol=\"tokens\", outputCol=\"raw_features\", numFeatures=300)\n",
        "tf_df = hashing_tf.transform(preprocessed_df)\n",
        "\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "idf_model = idf.fit(tf_df)\n",
        "final_df = idf_model.transform(tf_df)\n",
        "\n",
        "final_df = final_df.select(\"features\", \"sentiment\")\n",
        "final_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbTsCtwzQ2kW",
        "outputId": "effed14c-29e1-48e0-a590-928c021e3c00"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|features                                                                                                                                                                                                                                                                                                                                            |sentiment|\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|(300,[150,153],[1.4134446881581184,1.892920899293278])                                                                                                                                                                                                                                                                                              |1        |\n",
            "|(300,[165,187],[2.4892936587037084,2.4528739270803785])                                                                                                                                                                                                                                                                                             |1        |\n",
            "|(300,[13,15,49,89,99,129,140,142,150,180,206,247,255,257,283],[5.305475705018362,1.4074624078391675,2.6510847904263177,2.39174170009095,3.035020265268407,3.382111462571881,1.9187371649894427,3.066763749028271,1.4134446881581184,2.8425433045893036,3.1169661136976647,1.543005778308865,2.603532104074059,1.5664492168902375,2.458800598844918])|1        |\n",
            "|(300,[11,26,42,90,170],[3.453057432301862,1.1334095359883525,1.323737234640698,2.8608451726583577,2.262695854065395])                                                                                                                                                                                                                               |1        |\n",
            "|(300,[7,37,77,92,103,109,112,173,192,277,298],[3.0511766833743854,2.6063109476109547,3.2394158768311123,2.898102814479666,2.043952745191453,3.6442012907754715,2.3701303995410674,2.266286598941285,2.041375986798413,2.2328808556602766,2.981012601630794])                                                                                        |0        |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark.ml.feature import CountVectorizer, IDF\n",
        "\n",
        "#cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"rawFeatures\", vocabSize=1000, minDF=5)\n",
        "\n",
        "# Fit the CountVectorizer model and transform the data:\n",
        "#cv_model = cv.fit(preprocessed_df)\n",
        "#tf_df = cv_model.transform(preprocessed_df)"
      ],
      "metadata": {
        "id": "znSOETc7VAY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = final_df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "zJMgdwjiTUB3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(labelCol=\"sentiment\", featuresCol=\"features\", numTrees=10, maxDepth=6,\n",
        "                           featureSubsetStrategy=\"auto\", subsamplingRate=0.8)\n",
        "\n",
        "train_df.cache()\n",
        "\n",
        "rf_model = rf.fit(train_df)\n",
        "\n",
        "predictions = rf_model.transform(test_df)\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"sentiment\", metricName=\"areaUnderROC\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9iGDZDSTPRg",
        "outputId": "a899181e-1d37-4631-dafe-a662313a960b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7391002704451265\n"
          ]
        }
      ]
    }
  ]
}